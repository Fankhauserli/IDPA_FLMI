<!DOCTYPE html>
<html lang="de">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>IDPA FLMI</title>
    <link rel="stylesheet" href="/style.css">
    <style>
        /* Slider Container */
        .slider-container {
            position: relative;
            overflow: hidden;
            width: 100%;
            border-radius: 8px;
        }

        /* Slider Track */
        .answers-slider {
            display: flex;
            transition: transform 0.3s ease-in-out;
        }

        /* Individual Slide */
        .answer {
            flex: 0 0 100%;
            width: 100%;
            box-sizing: border-box;
            padding: 20px;
            background-color: #f9f9f9;
            border-radius: 8px;
        }

        .dark-section .answer {
            background-color: #333;
        }

        .answer h4 {
            margin-top: 0;
        }


        /* Dots Navigation */
        .slider-dots {
            position: absolute;
            bottom: 10px;
            /* Position from the bottom */
            left: 50%;
            /* Start from the middle */
            transform: translateX(-50%);
            /* Shift back by half its width to truly center */
            display: flex;
            /* Use flexbox for spacing dots */
            justify-content: center;
            /* Center dots within the flex container */
            gap: 8px;
            /* Space between dots */
            z-index: 10;
            /* Ensure dots are above other content */
        }

        .slider-dots .dot {
            cursor: pointer;
            height: 12px;
            width: 12px;
            background-color: #bbb;
            border-radius: 50%;
            display: inline-block;
            transition: background-color 0.3s ease;
        }

        .slider-dots .dot.active {
            background-color: #717171;
        }

        .collapsible-content-wrapper {
            overflow: hidden;
            transition: max-height 0.3s ease-out;
        }

        /* Style for the collapsible question summary */
        .collapsible-question summary {
            display: flex;
            align-items: center;
            /* Vertically align the arrow and text */
            cursor: pointer;
            padding: 10px 15px;
            /* Add padding around the summary */
            background-color: #f0f0f0;
            /* Light background for the summary */
            border: 1px solid #ddd;
            border-radius: 8px;
            margin-bottom: 10px;
            /* Space between summary and content */
            user-select: none;
            /* Prevent text selection on summary */
        }

        /* Hide default disclosure triangle */
        .collapsible-question summary::-webkit-details-marker {
            display: none;
        }

        .collapsible-question summary::marker {
            display: none;
        }

        /* Custom arrow icon using a pseudo-element */
        .collapsible-question summary::before {
            content: '‚ñ∫';
            /* Right-pointing triangle */
            font-size: 1.2em;
            margin-right: 10px;
            /* Space between arrow and text */
            color: #555;
            /* Color for the arrow */
            transform: rotate(0deg);
            transition: transform 0.2s ease-in-out;
            flex-shrink: 0;
            /* Prevent arrow from shrinking */
        }

        /* Rotate arrow when details is open */
        .collapsible-question[open] summary::before {
            transform: rotate(90deg);
            /* Down-pointing when open */
        }

        /* Style the h4 inside the summary for centering */
        .collapsible-question summary .chat-header {
            flex-grow: 1;
            /* Allow h4 to take available space */
            text-align: center;
            /* Center the text */
            margin: 0;
            /* Remove default h4 margins */
            color: #333;
            /* Darker text color */
        }


        /* On larger screens, show answers side-by-side */
        @media (min-width: 768px) {
            .answers-slider {
                display: grid;
                grid-template-columns: 1fr 1fr;
                gap: 20px;
                transform: none !important;
                /* Disable sliding transform */
            }

            .answer {
                flex-basis: auto;
                /* Reset flex-basis */
            }

            .slider-dots {
                display: none;
                /* Hide dots on desktop */
            }
        }
    </style>
</head>

<body>
    <div id="header-placeholder"></div>

    <main>
        <section id="home" class="hero">
            <h1 class="gradient-text">Erforschung von Fehlinformationen in LLMs</h1>
            <h2>Interdisziplin√§re Projektarbeit</h2>
            <p>Entdecken Sie, wie Large Language Models Fehlinformationen verbreiten und wie wir dem entgegenwirken
                k√∂nnen.</p>
            <a href="#einleitung" class="button">Tauchen Sie ein</a>
        </section>

        <section id="einleitung">
            <h2 class="gradient-text">Einleitung</h2>
            <p>In der heutigen digitalen Landschaft sind Large Language Models (LLMs) √ºberall pr√§sent. Sie bilden das
                Herzst√ºck fast aller modernen Chatbots. Diese Systeme beeindrucken durch ihre F√§higkeit, komplexe Texte
                zu generieren, die oft nicht mehr von menschlichen Formulierungen zu unterscheiden sind. Doch hinter der
                sprachlichen Eleganz verbirgt sich eine fundamentale Herausforderung: Die Modelle sind darauf trainiert,
                einen sachlichen und selbstbewussten Tonfall zu pflegen, unabh√§ngig davon, ob der Inhalt faktisch
                korrekt ist. Dies f√ºhrt zur sogenannten ¬´Autorit√§ts-Falle¬ª, bei der die Nutzer den plausibel klingenden,
                aber fehlerhaften Antworten, den sogenannten Halluzinationen, blind vertrauen.</p>
            <p>Unsere pers√∂nliche Motivation f√ºr diese Arbeit entspringt der Beobachtung, dass KI-Tools zwar bereits
                massenhaft im Alltag genutzt werden, das Wissen √ºber ihre technische Funktionsweise und ihre Grenzen
                jedoch oft fehlt. Viele Anwender:Innen nutzen diese m√§chtigen Werkzeuge, ohne zu wissen, wie sie durch
                die richtige Handhabung Fehler vermeiden oder die Zuverl√§ssigkeit der Ergebnisse steigern k√∂nnen. Wir
                m√∂chten mit dieser IDPA daher nicht nur die mathematische Komplexit√§t beleuchten, sondern vor allem f√ºr
                einen kompetenten und kritischen Umgang mit KI sensibilisieren.</p>
            <p>Da die Modelle lediglich berechnen, was statistisch ¬´plausibel¬ª klingt, stellt sich die Frage, ob wir
                jemals eine KI ohne Fehlinformationen erleben werden. Diese Arbeit setzt genau hier an und untersucht
                die tieferliegenden Mechanismen von der Vektoreinbettung bis hin zum Training durch Backpropagation.</p>
            <div class="dark-section">
                <h2>Fragestellung</h2>
                <p>Im Zentrum steht die Untersuchung unserer Leitfrage:</p>
                <h3>Inwiefern f√ºhren die mathematischen Grundlagen von Large Language Models zwangsl√§ufig zu
                    Halluzinationen
                    und welche Gegenmassnahmen sind wirksam?</h3>
            </div>
            <p>Die vorliegende Arbeit ist in drei wesentliche Abschnitte unterteilt:</p>
            <div class="topic-links-container">
                <div class="topic-box">
                    <h3>¬´Wie funktioniert ein LLM mathematisch?¬ª</h3>
                    <p>Um unsere Fragestellung zu beantworten, braucht man ein grundlegendes Verst√§ndnis von LLM. Daher
                        erl√§utern wir den Aufbau eines LLMs, angefangen bei der Mathematik eines einzelnen Neurons √ºber
                        die Bedeutung von Vektoren bis hin zur Transformer-Architektur.</p>
                </div>
                <div class="topic-box">
                    <h3>¬´Aus welchen Gr√ºnden halluzinieren LLMs?¬ª</h3>
                    <p>Wir untersuchen im Detail, wo technische Einschr√§nkungen zu Fehlinformationen f√ºhren. Damit wir
                        in einem n√§chsten Schritt gezielt nach L√∂sungen f√ºr diese Problemstellen suchen k√∂nnen.</p>
                </div>
                <div class="topic-box">
                    <h3>¬´Wie kann man Halluzinationen vermindern?¬ª</h3>
                    <p>Wir suchen m√∂gliche L√∂sungsans√§tze, um Halluzinationen entgegenzuwirken. Neben unserer Recherche
                        f√ºhren wir hier auch ein Interview mit Fachpersonen durch.</p>
                </div>
            </div>
            <p>Abschliessend ziehen wir ein Fazit, das sowohl technische Perspektiven f√ºr Entwickler als auch praktische
                Empfehlungen f√ºr die Anwendenden bereith√§lt, um die KI als wertvolles Werkzeug zu nutzen, ohne der
                ¬´Autorit√§ts-Falle¬ª zu erliegen.</p>
        </section>

        <section id="themen">
            <h2 class="gradient-text">√úbersicht</h2>
            <p>Um unsere Arbeit √ºbersichtlicher zu gestalten haben wir sie in folgende Bereiche unterteilt.</p>
            <div class="topic-links-container">
                <a href="/llm/" class="topic-link">
                    <div class="topic-box">
                        <h3>LLM</h3>
                        <p>Lernen Sie wie ein LLM funktioniert</p>
                        <span class="learn-more">Erfahre mehr</span>
                    </div>
                </a>
                <a href="/vorschlaege/" class="topic-link">
                    <div class="topic-box topic-box-special">
                        <h3>Unsere Vorschl√§ge</h3>
                        <p>Was k√∂nnen <strong>Sie</strong> gegen Fehlinformationen machen?</p>
                        <span class="learn-more">Erfahre mehr</span>
                    </div>
                </a>
                <a href="/anfaelligkeit/" class="topic-link">
                    <div class="topic-box">
                        <h3>Anf√§lligkeit</h3>
                        <p>Lernen Sie wie Fehler in LLM entstehen</p>
                        <span class="learn-more">Erfahre mehr</span>
                    </div>
                </a>
                <a href="#interview" class="topic-link">
                    <div class="topic-box">
                        <h3>Interview</h3>
                        <p>Interview mit Experten im LLM Bereich</p>
                        <span class="learn-more">Erfahre mehr</span>
                    </div>
                </a>
                <a href="#fazit" class="topic-link">
                    <div class="topic-box">
                        <h3>Fazit</h3>
                        <p>Unser Zusammenfassung der Erkenntnisse der IDPA</p>
                        <span class="learn-more">Erfahre mehr</span>
                    </div>
                </a>
            </div>
        </section>

        <section id="interview" class="tips">
            <h2 class="gradient-text">Interview</h2>
            <p>Um unsere Recherche mit Fachwissen abzust√ºrzen haben wir verschiedene Fachpersonen nach einem Interview
                gefragt. Urspr√ºnglich war die Idee jemanden aus der ETH Z√ºrich zu befragen, da dort mit "Apertus" vor
                k√ºrzerem ein eigenes LLM entwickelt wurde. Leider antwortete uns niemand auf unsere Anfrage zu einem
                Interview. Anschliessend fragten wir eine Person von einer Fachhochschule an. Innerhalb dieses
                Dokument haben wir den Namen der Person, aufgrund des Datenschutzes, geschw√§rzt. Als diese
                eine etwas merkw√ºrdige Antwort gab, interviewten wir Mikaela Buzdin, welche wir im pers√∂hnlichen
                Bekanntenkreis fanden.</p>
            <h4>Organisation Interview</h4>
            <p>Auf der Webseite einer Fachhochschule wurden wir anschliessend auf eine Person, welche im Bereich LLM
                t√§tig ist, aufmerksam. Wir beschlossen diese anzuschreiben und nach einem Interview zu bitten. Nach
                einer initialen Zusage zu einem Interview, waren wir etwas entt√§uscht, als uns mitgeteilt wurde wir
                sollen unsere Interview-Fragen mit ChatGPT oder Perprexity erarbeiten.</p>
            <div class="tip-box">
                <div class="chat-container">
                    <h5 class="chat-header">Mailverkehr mit der genannten Person:</h5>
                    <div class="message message-right">
                        <details class="collapsible-message">
                            <summary><strong>Wir:</strong>&nbspAnfrage f√ºr ein Interview</summary>
                            <div class="collapsible-content-wrapper">
                                <div class="collapsible-content">
                                    <p>Sehr geehrter X</p>
                                    <p>Mein Name ist Fabio Fl√ºckiger und ich schreibe Ihnen im Namen meines
                                        Lernendenteams¬†von der GIBB (Gewerblich Industrielle Berufsfachschule Bern),
                                        Berufsmaturit√§t. Im Rahmen unseres interdisziplin√§ren Projekts (IDPA)
                                        untersuchen wir das Verhalten¬†von Fehlinformationen innerhalb von k√ºnstlicher
                                        Intelligenz, insbesondere grosser Sprachmodelle (LLMs).</p>
                                    <p>Unsere zentrale Fragestellung lautet: "Wie kann bei K√ºnstlichen Intelligenzen¬†die
                                        Auswirkung von Falschinformationen technisch eingeschr√§nkt werden?‚Äú</p>
                                    <p>F√ºr den methodischen Teil unserer Arbeit, in dem wir die Struktur moderner
                                        Algorithmen und die Urspr√ºnge von Fehlinformationen analysieren, w√§re ein
                                        Interview mit einer Fachperson von unsch√§tzbarem Wert.¬†</p>
                                    <p>Wir sind durch die offizielle <span class="censored">Webseite der FH</span> auf
                                        <span class="censored">den T√§tigkeitsbereich der Person</span> aufmerksam
                                        geworden, bei welcher¬†Sie hinterlegt sind.
                                    </p>
                                    <p>H√§tten Sie Zeit f√ºr ein Interview? Wir k√∂nnen Ihnen die Fragen schriftlich
                                        zukommen lassen oder nach Terminvereinbarung das Interview per Videokonferenz,
                                        Telefon oder pers√∂nlich durchf√ºhren.</p>
                                    <p>Vielen Dank f√ºr Ihre Zeit und Ihre Aufmerksamkeit.</p>
                                    <p>Freundliche Gr√ºsse<br>
                                        Isaiah Dias<br>
                                        Linus Fankhauser<br>
                                        Mihailo Milosevic<br>
                                        Fabio Fl√ºckiger
                                    </p>
                                </div>
                            </div>
                        </details>
                    </div>
                    <div class="message message-left">
                        <details class="collapsible-message">
                            <summary><strong>X:</strong>&nbspZusage schriftliches Interview</summary>
                            <div class="collapsible-content-wrapper">
                                <div class="collapsible-content">
                                    <p>Lieber Fabio Fl√ºckiger</p>
                                    <p>Ihr k√∂nnt mir gerne eure Fragen schriftlich schicken, ich kann sie beantworten
                                        oder an eine entsprechende Fachperson weiterleiten.</p>
                                    <p>Viel Erfolg mit der Arbeit</p>
                                    <p>Mit freundlichem Gruss</br>
                                        X</p>
                                </div>
                            </div>
                        </details>
                    </div>
                    <div class="message message-right">
                        <details class="collapsible-message">
                            <summary><strong>Wir:</strong>&nbspInterviewfragen</summary>
                            <div class="collapsible-content-wrapper">
                                <div class="collapsible-content">
                                    <p>Guten Tag Herr X</p>
                                    <p>Ihre Antwort freut uns enorm. Vielen Dank.</p>
                                    <p>Es w√ºrde uns freuen, wenn Sie folgende Fragen beantworten k√∂nnten. Wir haben uns
                                        schon etwas l√§nger mit dem Thema LLM‚Äôs auseinandergesetzt und schliessen alle
                                        dieses Jahr die Lehre als Informatiker EFZ ab. Somit bitten wir Sie, die Fragen
                                        m√∂glichst detailiert zu beantworten.</p>
                                    <ul>
                                        <li>Warum treten Halluzinationen auf? Was sind die Problemstellen innerhalb
                                            einer LLM / eines Transformers?</li>
                                        <li>Ist es m√∂glich, ein RAG-System aufzubauen, welches die Informationen direkt
                                            aus dem Internet bezieht? (somit verl√§sst man sich nicht nur auf die
                                            Trainingsdaten ‚Äì kann dies ein L√∂sungsansatz gegen Halluzinationen sein?)
                                        </li>
                                        <li>Wird das Problem von Fehlinformationen durch das Skalieren der LLM behoben?
                                        </li>
                                        <li>Welche Entwicklungen hatten bis jetzt den gr√∂ssten Einfluss auf die
                                            Fehlerquote?</li>
                                        <li>Welche Massnahmen werden aktuell entwickelt oder erforscht, um
                                            Halluzinationen weiter zu verhindern?</li>
                                        <li>Was k√∂nnen private Anwender von ChatBots machen, um Halluzinationen zu
                                            verhindern?</li>
                                        <li>Wie gross sch√§tzen Sie die Auswirkung von gutem Prompt-Engineering?</li>
                                        <li>Bringt es einen messbaren Mehrwert, wenn das Modell seine eigene Antwort in
                                            einem zweiten Schritt √ºberpr√ºft?</li>
                                        <li>Denken Sie, dass wir bei der ¬´Next-Token-Prediction¬ª an ein Limit stossen
                                            werden?</li>
                                        <li>Sollten wir unsere Zeit in die Forschung f√ºr neue Algorithmen investieren,
                                            welche einen anderen Ansatz verfolgen?</li>
                                    </ul>
                                    <p>Damit wir Sie kurz in unserer Arbeit vorstellen k√∂nnen, w√ºrden wir uns zus√§tzlich
                                        √ºber einen kurzen Steckbrief freuen. Besonders die Frage inwiefern Sie mit LLM‚Äôs
                                        zu tun haben.</p>
                                    <p>Wir danken Ihnen f√ºr Ihre Bereitschaft und sind gespannt auf Ihre Antworten.</p>
                                    <p>
                                        Freundliche Gr√ºsse<br>
                                        Mihailo Milosevic<br>
                                        Isaiah Dias<br>
                                        Linus Fankhauser<br>
                                        Fabio Fl√ºckiger
                                    </p>
                                </div>
                            </div>
                        </details>
                    </div>
                    <div class="message message-left">
                        <details class="collapsible-message">
                            <summary><strong>X:</strong>&nbspL√∂sungsansatz</summary>
                            <div class="collapsible-content-wrapper">
                                <div class="collapsible-content">
                                    <p>Lieber Fabio</p>
                                    <p>Danke f√ºr deine Fragestellungen. Diese Fragen sind sinnvoll und gut formuliert.
                                        Sie sind aber auch knifflig und haben nicht unbedingt eindeutige Antworten.</p>
                                    <p>Die Beantwortung dieser Fragen ist aber eigentlich der Inhalt eurer Projektarbeit
                                        und nicht meine Aufgabe, sondern eure üòä.</p>
                                    <p>Ich schlage euch vor, ihr sucht nach ersten Antworten mit ChatGPT oder Copilot
                                        usw, und auch nach einer Antwort f√ºr das Gesamt Thema eurer Semesterarbeit √†
                                        danach jede Frage vielleicht pr√§ziser stellen und nach Beispielen fragen.</p>
                                    <p>Ebenfalls k√∂nnt ihr nach B√ºchern oder Publikationen suchen eurem Thema: ein guter
                                        Ort ist das Literatursuchprogramm elicit.com, oder perplexity.ai</p>
                                    <p><strong>Am Schluss erstellt ihr eine Liste mit den 5-10 wichtigsten Faktoren,
                                            welche die Projektfrage beantworten "Wie kann bei K√ºnstlichen
                                            Intelligenzen¬†die Auswirkung von Falschinformationen technisch eingeschr√§nkt
                                            werden?‚Äú</strong></p>
                                    <p><strong>Zu jedem Faktor Hinweise, was zu tun ist, und ein Beispiel.</strong></p>
                                    <p>Gerne hier meine erste Anfrage bei Perplexity ¬†( gute √úbersicht meines Erachtens)
                                    </p>
                                    <p><a href="https://www.perplexity.ai/search/wie-kann-bei-kunstlichen-intel-3EBYzBdbSuS1x.QWbQjjvg#0"
                                            target="_blank">https://www.perplexity.ai/search/wie-kann-bei-kunstlichen-intel-3EBYzBdbSuS1x.QWbQjjvg#0</a>
                                    </p>
                                    <p>und ChatGPT</p>
                                    <p><a href="https://chatgpt.com/share/69678a57-489c-8006-8b25-d7c0fd8f4eb2"
                                            target="_blank">https://chatgpt.com/share/69678a57-489c-8006-8b25-d7c0fd8f4eb2</a>
                                    </p>
                                    <p>Mit freundlichem Gruss</p>
                                    <p>X</p>
                                </div>
                            </div>
                        </details>
                    </div>
                </div>
            </div>
            <p>Wir wissen nicht, warum die Person die Fragen nicht selbst√§ndig beantwortet hat. Vielleicht gab es ein
                Missverst√§ndnis und er dachte er w√ºrde durch das Beantworten der Frage unsere Recherche √ºbernehmen.
                Wobei wir viel mehr seine pers√∂nliche Meinung erfahren wollten. M√∂glicherweise waren unsere Fragen auch
                zu simpel und er wollte uns auffordern, uns noch tiefer ins Thema einzulesen. Eine weitere Option
                besteht darin, dass wir mit unserer Recherche in ein Gebiet vorgestossen sind, in welchem es selbst f√ºr
                Fachpersonen schwer ist Aussagen zu treffen. Entsprechend seiner Empfehlung haben wir die
                Interview-Fragen
                mit einer k√ºnstlichen Intelligenz erarbeitet.</p>
            <p>Nun haben wir Fragen, √ºber Fehlinformationen und Halluzinationen innerhalb k√ºnstlicher Intelligenz, mit
                einer k√ºnstlichen Intelligenz beantworten lassen. Aufgrund dieser Ironie haben wir uns entschlossen,
                weiter nach einem m√∂glichen Interview Ausschau zu halten. Im erweiterten Bekanntenkreis stiessen wir auf
                Mikaela, gelehrte Informatikerin Applikationsentwicklung EFZ und im letzten Semester des Studienganges
                "BSc Data Science &amp; Artificial Intelligence" an der Fachhochschule Nordwestschweiz (FHNW). Neben dem
                Studium arbeitet Mikaela aktuell an einem generativen KI-Projekt, welches mit Transformer-√§hnlichen
                Strukturen (TRELLIS) arbeitet. Das Ziel dieses Projektes ist es 3D Rekonstruktion aus 2D Bildern zu
                erstellen. Weitere Informationen √ºber ihr Werdegang k√∂nnen in ihrem <a
                    href="https://dpoportfolio-mikaela.onrender.com/" target="_blank">Portfolio</a> gefunden werden.</p>
            <details class="collapsible-question">
                <summary>
                    <h4 class="chat-header">Interview Fragen und Antworten</h4>
                </summary>
                <div class="collapsible-content-wrapper">
                    <div class="collapsible-content">
                        <div class="question-block">
                            <h5 class="chat-header">Warum treten Halluzinationen auf?</h5>
                            <div class="answers-container slider-container">
                                <div class="answers-slider">
                                    <div class="answer">
                                        <h4>KI-generierte Antwort</h4>
                                        <p>Halluzinationen entstehen prim√§r dadurch, dass Transformer als reine
                                            Vorhersagesysteme f√ºr das n√§chste Textelement konzipiert sind und √ºber kein
                                            internes Verst√§ndnis von Wahrheit oder Fakten verf√ºgen. Da diese Modelle
                                            darauf trainiert werden, menschliche Sprache und Schreibstile zu imitieren,
                                            priorisieren sie oft die Plausibilit√§t und den sprachlichen Fluss gegen√ºber
                                            der faktischen Korrektheit. Problemstellen liegen insbesondere in
                                            Wissensl√ºcken innerhalb der Trainingsdaten sowie in einer mangelhaften
                                            Kalibrierung, die dazu f√ºhrt, dass das Modell bei Unsicherheit oder
                                            fehlender Evidenz dennoch eine Antwort generiert. Zus√§tzliche Fehlerquellen
                                            ergeben sich durch Abweichungen zwischen dem Trainingszeitpunkt und der
                                            aktuellen Anfrage sowie durch Ungenauigkeiten im Abrufprozess externer
                                            Informationen, was insgesamt zu einer Diskrepanz zwischen statistischer
                                            Wahrscheinlichkeit und realer Faktenlage f√ºhrt.</p>
                                        <p style="font-size: 0.8em; color: #666; margin-top: 10px;">Quelle: <a
                                                href="https://gemini.google.com/share/16e1eedaea84"
                                                target="_blank">https://gemini.google.com/share/16e1eedaea84</a></p>
                                    </div>
                                    <div class="answer">
                                        <h4>Antwort von Mikaela</h4>
                                        <p>Halluzinationen k√∂nnen aus vielen Quellen entstehen, beispielsweise durch
                                            Overfitting oder Underfitting, je nachdem, wie die Trainingsdaten und/oder
                                            die Struktur des Transformers/LLMs sind oder wie einige Prozesse w√§hrend der
                                            Datenaufbereitung stattfanden. Ein leicht illustrierbares Beispiel, das in
                                            letzter Zeit viel Aufmerksamkeit erhalten hat, ist die Frage ‚ÄûIs there a
                                            seahorse emoji?‚Äù bei ChatGPT. Da ChatGPT auf Next-Word-Prediction trainiert
                                            wurde und kein Seahorse-Emoji kennt, fiel es aufgrund interner Gewichte in
                                            einen langen Loop, in dem es sich dachte: ‚ÄûJa, ich kenne das
                                            Seahorse-Emoji‚Äù, ein falsches Emoji postete, sich dann entschuldigte und
                                            wieder von vorne begann.</p>
                                    </div>
                                </div>
                                <div class="slider-dots"></div>
                            </div>
                        </div>
                        <div class="question-block">
                            <h5 class="chat-header">Ist es m√∂glich, ein RAG-System aufzubauen, welches die Informationen
                                direkt aus dem Internet bezieht?</h5>
                            <div class="answers-container slider-container">
                                <div class="answers-slider">
                                    <div class="answer">
                                        <h4>KI-generierte Antwort</h4>
                                        <p>Technisch ist dies absolut m√∂glich, indem man Sprachmodelle mit einer
                                            Live-Suche kombiniert und die gefundenen Dokumente direkt als Kontext f√ºr
                                            die Antwortgenerierung nutzt. Dieses Verfahren hilft oft effektiv gegen
                                            Halluzinationen, da die Aussagen auf aktuell recherchierten und
                                            verifizierten Fakten basieren statt rein auf dem Modellwissen. Der Erfolg
                                            h√§ngt jedoch massgeblich von der Qualit√§t der Quellen und der Abrufmechanik
                                            ab, da ungenaue Suchergebnisse sonst lediglich zu neuen Fehlern f√ºhren
                                            w√ºrden.</p>
                                        <p style="font-size: 0.8em; color: #666; margin-top: 10px;">Quelle: <a
                                                href="https://gemini.google.com/share/473dfcb65adb"
                                                target="_blank">https://gemini.google.com/share/473dfcb65adb</a></p>
                                    </div>
                                    <div class="answer">
                                        <h4>Antwort von Mikaela</h4>
                                        <p>Ja, es w√§re m√∂glich, aber es ist eine schreckliche Idee, die die
                                            ‚ÄûHalluzinationen‚Äù nur verschlimmert. Wenn wir Live-Daten aus dem Internet
                                            beziehen, beziehen wir unglaublich viele unverifizierte Informationen, oft
                                            auch Informationen, die sich direkt widersprechen. Wenn wir wahllos Daten
                                            aus dem Internet beziehen, f√ºgen wir unserem Datensatz nur mehr Rauschen
                                            hinzu. Und auch wenn diese Daten eine Ahnung von aktuellen Themen haben,
                                            sind sie wahrscheinlich inkorrekt und somit ein grosses Risiko f√ºr Firmen,
                                            die LLMs anbieten. Wenn wir rein hypothetisch ein System aufbauen, das Daten
                                            automatisch korrekt und gut recherchiert bezieht, w√§re dies m√∂glich und
                                            k√∂nnte Halluzinationen verringern. Das rigorose √úberpr√ºfen der aktuell schon
                                            vorhandenen Daten w√§re jedoch ein gleichwertiger, wenn nicht sogar besserer
                                            Ansatz, um Halluzinationen zu verhindern. Oft sind aktuelle Themen auch noch
                                            entwickelnde Geschichten bei welchen Halbwahrheiten und Rumore Vortritt vor
                                            Fakten nehmen.</p>
                                    </div>
                                </div>
                                <div class="slider-dots"></div>
                            </div>
                        </div>
                        <div class="question-block">
                            <h5 class="chat-header">Wird das Problem von Fehlinformationen durch das Skalieren der LLM
                                behoben?</h5>
                            <div class="answers-container slider-container">
                                <div class="answers-slider">
                                    <div class="answer">
                                        <h4>KI-generierte Antwort</h4>
                                        <p>Das reine Skalieren von Modellen behebt das Problem der Fehlinformation nicht
                                            zuverl√§ssig. Zwar verbessern sich mit zunehmender Gr√∂sse viele F√§higkeiten
                                            und die Fehlerrate sinkt, doch die Wahrhaftigkeit steigt dabei nicht
                                            automatisch linear an. Gr√∂ssere Modelle sind folglich nicht zwingend
                                            ehrlicher, weshalb gezielte Anpassungen wie Instruction-Tuning oft
                                            entscheidender sind als reine Modellgr√∂sse.</p>
                                        <p style="font-size: 0.8em; color: #666; margin-top: 10px;">Quelle: <a
                                                href="https://gemini.google.com/share/41a74bcf8c8e"
                                                target="_blank">https://gemini.google.com/share/41a74bcf8c8e</a></p>
                                    </div>
                                    <div class="answer">
                                        <h4>Antwort von Mikaela</h4>
                                        <p>Das Problem l√§sst sich durch Skalierung und mehr Informationen reduzieren.
                                            Mehr Verst√§ndnis dieser Informationen f√ºhrt nat√ºrlich zu einer Verminderung
                                            solcher Fehlinformationen. Eine vollst√§ndige Behebung wird jedoch nie
                                            m√∂glich sein, solange Fehlinformationen in der Welt existieren ‚Äì was sie
                                            vorhersehbar immer tun werden.</p>
                                    </div>
                                </div>
                                <div class="slider-dots"></div>
                            </div>
                        </div>
                        <div class="question-block">
                            <h5 class="chat-header">Welche Entwicklungen hatten bis jetzt den gr√∂ssten Einfluss auf die
                                Fehlerquote?</h5>
                            <div class="answers-container slider-container">
                                <div class="answers-slider">
                                    <div class="answer">
                                        <h4>KI-generierte Antwort</h4>
                                        <p>Den gr√∂ssten Einfluss hatten effizientere Trainingsmethoden zur Balance von
                                            Daten und Rechenleistung sowie die gezielte Ausrichtung der Modelle durch
                                            menschliches Feedback. Erg√§nzend dazu reduzierten der Zugriff auf externe
                                            Quellen zur Faktenpr√ºfung und spezielle Eingabetechniken f√ºr logische
                                            Schlussfolgerungen die Fehlerraten erheblich, wobei erst pr√§zisere
                                            Messverfahren eine solch gezielte Optimierung der Wahrheitstreue m√∂glich
                                            machten.</p>
                                        <p style="font-size: 0.8em; color: #666; margin-top: 10px;">Quelle: <a
                                                href="https://gemini.google.com/share/f1577ac31a56"
                                                target="_blank">https://gemini.google.com/share/f1577ac31a56</a></p>
                                    </div>
                                    <div class="answer">
                                        <h4>Antwort von Mikaela</h4>
                                        <p>Es gibt viele verschiedene Ans√§tze, die der Entwicklung von LLMs helfen
                                            k√∂nnen. Human Feedback ist immer ein starker Kandidat f√ºr Verbesserungen.
                                            Auch generelle Erl√§uterungen bei schwierigen Themen, bei denen sich KI nicht
                                            sicher ist und dies auch klarmacht, sind hilfreich. Jedoch bin ich nicht
                                            intim besch√§ftigt mit der Historie der Entwicklung von Large Language
                                            Modellen, es steht sicher noch mehr Online dazu als ich hier vermittle.</p>
                                    </div>
                                </div>
                                <div class="slider-dots"></div>
                            </div>
                        </div>
                        <div class="question-block">
                            <h5 class="chat-header">Welche Massnahmen werden aktuell entwickelt oder erforscht, um
                                Halluzinationen weiter zu verhindern?</h5>
                            <div class="answers-container slider-container">
                                <div class="answers-slider">
                                    <div class="answer">
                                        <h4>KI-generierte Antwort</h4>
                                        <p>Die Forschung konzentriert sich aktuell stark auf die Weiterentwicklung von
                                            Retrieval-Augmented Generation, indem iterative Korrekturprozesse und
                                            dynamische Suchverfahren integriert werden, die Informationen erst bei
                                            explizitem Bedarf abrufen. Parallel dazu werden Mechanismen etabliert, die
                                            Modelle dazu zwingen, ihre eigenen Aussagen durch Verifikationsketten zu
                                            pr√ºfen, externe Werkzeuge zur inhaltlichen Entlastung zu nutzen oder
                                            Antworten bei Unsicherheit und fehlenden Belegen g√§nzlich zu verweigern.</p>
                                        <p style="font-size: 0.8em; color: #666; margin-top: 10px;">Quelle: <a
                                                href="https://gemini.google.com/share/37a5f038ca2f"
                                                target="_blank">https://gemini.google.com/share/37a5f038ca2f</a></p>
                                    </div>
                                    <div class="answer">
                                        <h4>Antwort von Mikaela</h4>
                                        <p>Auch hier bin ich keine Expertin, mir ist jedoch bewusst, dass es seit
                                            einiger Zeit ein erh√∂htes Interesse an der Erkl√§rbarkeit von KI gibt,
                                            insbesondere in LLMs. Es geht darum, zu untersuchen, was genau in den
                                            verschiedenen Gewichten und Vorurteilen eines Layers abl√§uft und wie allein
                                            schon die Einbettungen auf einer intimen und intuitiven Ebene erkl√§rt werden
                                            k√∂nnen ist noch ein entwickelndes Thema, welches uns auch hilft exakte
                                            Massnahmen zu treffen um LLMs in diesen Ans√§tzen zu verbessern.</p>
                                    </div>
                                </div>
                                <div class="slider-dots"></div>
                            </div>
                        </div>
                        <div class="question-block">
                            <h5 class="chat-header">Was k√∂nnen private Anwender von ChatBots machen, um Halluzinationen
                                zu verhindern?</h5>
                            <div class="answers-container slider-container">
                                <div class="answers-slider">
                                    <div class="answer">
                                        <h4>KI-generierte Antwort</h4>
                                        <p>Private Anwender k√∂nnen Halluzinationen effektiv entgegenwirken, indem sie
                                            konsequent Belege wie Zitate oder Links einfordern und bevorzugt Modi mit
                                            aktiver Internetrecherche nutzen. Zudem empfiehlt es sich, das Modell
                                            anzuweisen, bei Unsicherheit zu schweigen, sowie Antworten durch mehrfache
                                            Abfragen auf ihre Konsistenz zu pr√ºfen und komplexe Fragen in einzeln
                                            verifizierbare Fakten zu zerlegen.</p>
                                        <p style="font-size: 0.8em; color: #666; margin-top: 10px;">Quelle: <a
                                                href="https://gemini.google.com/share/febe989dc02a"
                                                target="_blank">https://gemini.google.com/share/febe989dc02a</a></p>
                                    </div>
                                    <div class="answer">
                                        <h4>Antwort von Mikaela</h4>
                                        <p>Exaktes und einheitliches prompten, es gibt viele Arten wie man LLMs prompten
                                            kann um mehr Informationen zu gewinnen √ºber den Generierungsprozess.
                                            Ebenfalls haben LLMs einen limitierten Kontext, somit sollte man Vorsichtig
                                            sein viele Sachen auf einmal zu Fragen. Ich kann empfehlen oft nach Quellen
                                            von Antworten zu fragen und diese zu √ºberpr√ºfen und jeweils nur 1 Frage pro
                                            Nachricht zu senden.</p>
                                    </div>
                                </div>
                                <div class="slider-dots"></div>
                            </div>
                        </div>
                        <div class="question-block">
                            <h5 class="chat-header">Wie gross sch√§tzen Sie die Auswirkung von gutem Prompt-Engineering?
                            </h5>
                            <div class="answers-container slider-container">
                                <div class="answers-slider">
                                    <div class="answer">
                                        <h4>KI-generierte Antwort</h4>
                                        <p>Die Auswirkung ist empirisch substanziell, jedoch stark von der jeweiligen
                                            Aufgabe abh√§ngig. Zwar k√∂nnen gezielte Strukturierung und Methoden wie
                                            Chain-of-Thought die Fehlerquoten massgeblich senken und das Reasoning
                                            verbessern, sie ersetzen jedoch kein fundiertes Grounding.</p>
                                        <p style="font-size: 0.8em; color: #666; margin-top: 10px;">Quelle: <a
                                                href="https://gemini.google.com/share/f881278bfb1b"
                                                target="_blank">https://gemini.google.com/share/f881278bfb1b</a></p>
                                    </div>
                                    <div class="answer">
                                        <h4>Antwort von Mikaela</h4>
                                        <p>Prompt-Engineering kann dem Output massiv helfen das zu kriegen was man
                                            erwartet, mehr Kontext verhilft Sprachmodellen exaktere Quellen zu beziehen
                                            und Outputs nach diesen Quellen zu produzieren.</p>
                                    </div>
                                </div>
                                <div class="slider-dots"></div>
                            </div>
                        </div>
                        <div class="question-block">
                            <h5 class="chat-header">Bringt es einen messbaren Mehrwert, wenn das Modell seine eigene
                                Antwort in einem zweiten Schritt √ºberpr√ºft?</h5>
                            <div class="answers-container slider-container">
                                <div class="answers-slider">
                                    <div class="answer">
                                        <h4>KI-generierte Antwort</h4>
                                        <p>Eine √úberpr√ºfung im zweiten Schritt bietet oft messbaren Mehrwert, indem sie
                                            durch iterative Feedbackschlaufen oder das Abw√§gen mehrerer L√∂sungswege zu
                                            robusteren Antworten f√ºhrt und Halluzinationen reduziert.</p>
                                        <p>Dieser Nutzen ist allerdings nicht garantiert, da die Zuverl√§ssigkeit der
                                            Selbstkorrektur stark vom Setup sowie dem jeweiligen Evaluationsmass abh√§ngt
                                            und negative Befunde zeigen, dass Modelle ihre Antworten nicht in jedem
                                            Kontext erfolgreich verbessern.</p>
                                        <p style="font-size: 0.8em; color: #666; margin-top: 10px;">Quelle: <a
                                                href="https://gemini.google.com/share/bc31629f968c"
                                                target="_blank">https://gemini.google.com/share/bc31629f968c</a></p>
                                    </div>
                                    <div class="answer">
                                        <h4>Antwort von Mikaela</h4>
                                        <p>Nein, ein und dasselbe Modell w√ºrde nur seine eigenen Verzerrungen und Fehler
                                            verst√§rken. Auch wenn man ein anderes Modell n√ºtzt hilft man hier nur wenig,
                                            das kein Modell an sich eine Wahrheitsbasis besitzt.</p>
                                    </div>
                                </div>
                                <div class="slider-dots"></div>
                            </div>
                        </div>
                        <div class="question-block">
                            <h5 class="chat-header">Denken Sie, dass wir bei der ¬´Next-Token-Prediction¬ª an ein Limit
                                stossen werden?</h5>
                            <div class="answers-container slider-container">
                                <div class="answers-slider">
                                    <div class="answer">
                                        <h4>KI-generierte Antwort</h4>
                                        <p>Zwar skaliert Next-Token-Prediction gem√§ss den bekannten Gesetzen erstaunlich
                                            weit und profitiert stetig von mehr Rechenleistung, doch stossen wir bei
                                            Anforderungen wie Wahrheitstreue, langfristiger Planung und Werkzeugnutzung
                                            an qualitative Grenzen. Da reine Vorhersagemodelle keine Faktenreue
                                            garantieren, liegt der Fortschritt nicht allein in der weiteren Skalierung,
                                            sondern in der Erg√§nzung durch Mechanismen wie Retrieval und Verifikation,
                                            um diese strukturellen L√ºcken zu schliessen.</p>
                                        <p style="font-size: 0.8em; color: #666; margin-top: 10px;">Quelle: <a
                                                href="https://gemini.google.com/share/ea56ae772f1e"
                                                target="_blank">https://gemini.google.com/share/ea56ae772f1e</a></p>
                                    </div>
                                    <div class="answer">
                                        <h4>Antwort von Mikaela</h4>
                                        <p>Das h√§ngt davon ab, was hier mit dem Limit von genau gemeint ist. Nat√ºrlich
                                            ist eine Next-Token-Prediction nicht f√ºr Anwendungsf√§lle ausserhalb der
                                            Sprache optimal. Mit Transformer-Modellen, die viele verschiedene
                                            Architekturen nutzen, k√∂nnen wir jedoch Modelle bauen, die f√ºr verschiedene
                                            Aufgaben viel besser geeignet sind. Aktuell sind wir ja auch schon weiter
                                            als nur ‚ÄûNext-Token-Prediction‚Äú und moderne Architekturen arbeiten mit
                                            verschiedenen Tasks zur Optimierung.</p>
                                    </div>
                                </div>
                                <div class="slider-dots"></div>
                            </div>
                        </div>
                        <div class="question-block">
                            <h5 class="chat-header">Sollten wir unsere Zeit in die Forschung f√ºr neue Algorithmen
                                investieren, welche einen anderen Ansatz verfolgen?</h5>
                            <div class="answers-container slider-container">
                                <div class="answers-slider">
                                    <div class="answer">
                                        <h4>KI-generierte Antwort</h4>
                                        <p>Strategisch gesehen deutet die aktuelle Evidenz darauf hin, dass wir weniger
                                            in isolierte Alternativen, sondern in hybride Ans√§tze investieren sollten.
                                            Besonders erfolgversprechend ist die Kombination aus Generierung, Recherche
                                            und Verifikation sowie der Einsatz von Sprachmodellen zur Steuerung externer
                                            Werkzeuge, um durch systematisches Verst√§ndnis bestehende Forschungsl√ºcken
                                            effektiv zu schliessen.</p>
                                        <p style="font-size: 0.8em; color: #666; margin-top: 10px;">Quelle: <a
                                                href="https://gemini.google.com/share/b0340b616781"
                                                target="_blank">https://gemini.google.com/share/b0340b616781</a></p>
                                    </div>
                                    <div class="answer">
                                        <h4>Antwort von Mikaela</h4>
                                        <p>Ja, grunds√§tzlich schon. Es gibt noch sehr viel Arbeit im Umfeld von KI und
                                            insbesondere von Transformer-Modellen in allen m√∂glichen Richtungen:
                                            Performance, Rechenzeit, Erkl√§rbarkeit, Stromverbrauch usw. Wie schon zuvor
                                            sollten wir uns weiterhin bem√ºhen, neue Architekturen und Modellans√§tze zu
                                            entwickeln.</p>
                                    </div>
                                </div>
                                <div class="slider-dots"></div>
                            </div>
                        </div>
                    </div>
                </div>
            </details>
            <h4>Auswertung des Interviews</h4>
            <p>Die beiden Interviews, sowohl mit Mikaela wie auch mit der generativen KI, erm√∂glichen uns nun die Themen
                aus zwei unterschiedlichen Blickwinkeln zu analysieren. W√§hrend Gemini die Fragen in den meisten F√§llen
                sehr allgemeing√ºltig beantwortete, hatte Mikaela eine klarere Meinung zu den Themen und distanzierte
                sich auch offiziell von Fragen, bei welchen sie nicht ausreichend Fakten hatte.</p>
            <p>Im Interview wird klar, dass private Anwender am meisten beeinflussen k√∂nnen, indem sie durch Prompt
                Engineering ihre Prompts verbessern und nach Quellen fragen, welche sie anschliessend unabh√§ngig von dem
                LLM √ºberpr√ºfen. Auch die korrekte Verwendung von verschiedenen Chats und der Online-Suchfunktion wird
                erw√§hnt.</p>
            <p>Aus den Antworten ist ersichtlich, dass es bei der Entwicklung von LLM drei unterschiedliche Bereiche
                gibt,
                welche zur Verhinderung von Fehlinformation n√ºtzlich sein k√∂nnen. Es kann die LLM-Architektur angepasst
                werden, beim Training des LLM anders vorgegangen werden oder Umsystemen verwendet werden. Laut Gemini
                st√∂sst auch die "Next-Token-Prediction" irgendwann an ein Limit, da die Vorhersage von n√§chsten Worten
                keine Faktenchecks beinhaltet. Gerade hier erw√§hnt Mikaela, dass wir schon viel weiter sind als diese
                Vorhersage. Zum Beispiel RLHF war im Training eine sehr effektive Variante, um Halluzinationen weiter
                einzud√§mmen. Zus√§tzlich erw√§hnt Mikaela, dass auch intern im Aufbau eines Transformers schon viel
                angepasst wurde. Durch das Verschieben oder Neuanordnen von Komponenten k√∂nnen andere Ziele erreicht
                werden. Umsysteme bieten zwar einen grossen Mehrwert, verschieben aber das Problem meist nur auf einen
                anderen Punkt. Bei RAG hat man beispielsweise das Problem, dass bei steigender Gr√∂sse nicht mehr alle
                Quellen verifiziert, werden k√∂nnen.</p>
            <p>Zus√§tzlich ist uns beim Auswerten des Interviews noch etwas Weiteres aufgefallen. Gemini antwortete, dass
                aktuell Mechanismen entwickelt werden, damit LLM Antworten bei fehlenden Quellen oder Unsicherheiten
                verweigern k√∂nnen. Mikaela hat sich bei zwei Fragen distanziert und mit Aussagen wie "bin ich keine
                Expertin" klargemacht, dass die Fakten nicht vollst√§ndig sind oder sie etwas unsicher ist.</p>
            <p>Das w√§re f√ºr LLM sicherlich eine der gr√∂ssten Entwicklungen gegen Halluzinationen. Wenn eine LLM
                Situationen erkennt, in welchen zu wenig Belege vorhanden sind, und diese anschliessend markiert, h√§tten
                die Benutzer einen ersten Anhaltspunkt, wie wahrheitsgetreu die Antwort sein kann.</p>
            <p>Eine grosse Erkenntnis aus dem Mailverkehr mit der Person, von der Fachhochschule, und dem Interview war,
                dass unsere Fragestellung immer noch zu allgemein gehalten war. Daher passten wir diese noch w√§hrend der
                Arbeit an.</p>
        </section>
        <section id="fazit" class="gradient-section">
            <h2>Fazit</h2>
            <p>Am Anfang dieser Arbeit haben wir uns eine √ºbergeordnete Fragestellung √ºberlegt und davon mehrere
                untergeordnete Fragen abgeleitet. Dadurch k√∂nnen wir nun die √ºbergeordnete Fragestellung
                "Inwiefern f√ºhren die mathematischen Grundlagen von Large Language Models zwangsl√§ufig zu
                Halluzinationen welche Gegenmassnahmen sind wirksam?" beantworten.</p>

            <h3>Wie funktioniert ein Large Language Model mathematisch?</h3>
            <p>Damit wir das fundamentale Verst√§ndnis f√ºr LLMs erhielten, haben wir zuerst erarbeitet, wie ein LLM
                mathematisch aufgebaut ist. Es gibt viele verschiedene LLM-Architekturen. W√§hrend der Arbeit haben wir
                die Transformer-Architektur weiter angeschaut. Bei Transformern werden W√∂rter, vom Input, zuerst in
                Vektoren umgewandelt. Danach durchlaufen diese Vektoren die Attention. Innerhalb der Attention wird,
                mithilfe von mehreren Matrixmultiplikationen, Skalar Berechnungen und Softmax Funktionen, dem LLM
                erm√∂glicht den Kontext von Worten zu verstehen. Im darauffolgenden MLP, wird ein neurales Netzwerk
                verwendet, welches das Speichern von Informationen innerhalb des LLM erm√∂glicht. Auch hier werden
                Matrixmultiplikationen, Vektor Rechnungen und eine Funktion wie beispielsweise ReLU verwendet. Nach
                meheren Wiederholungen, der Attention und des MLP, kann das LLM angeben, welches Wort als n√§chstes
                besten auf den Gegebenen Text passt.</p>

            <h3>Aus welchen Gr√ºnden halluzinieren LLMs?</h3>
            <p>Erst w√§hrend der Recherche f√ºrs Thema wurde uns bewusst, dass die Architektur der aktuellen AI
                zwangsl√§ufig zu Halluzinationen f√ºhrt. Dies ist kein Fehler in der Software, sondern ein Teil des
                fundamentalen Prinzips, der Next-Token-Prediction. Es priorisiert eine plausibel klingende Antwort √ºber
                die faktisch korrekte. Zudem hat das LLM kein "Wissen", es hat lediglich Milliarden von Parametern, die
                dieses "Wissen" beinhalten. Das f√ºhrt immer dazu, dass ein gewisser Teil falsch sein musss, denn man
                kann nicht alle Informationen der Welt in einigen hundert Gigabytes ohne Verlust abspeichern.</p>
            <p>Im Embedding k√∂nnen √§hnliche Vektore etwas essenziell anderes bedeutet. Falls das LLM den falschen
                Vektor verwendet kann dadurch die komplette Generation beeinlusst werden. Sobald eine Fehlinformation,
                zum Beispiel durch das Prompt des Benutzers, in die Attention gelangt, wird die Attention darauf
                aufbauen. Dies f√ºhrt dazu, dass die Antwort deutlich von der Wahrheit abweichen kann.</p>
            <p>Unsere Recherche st√ºtzen wir zus√§tzlich mit einem Interview. Grunds√§tzlich √ºberschnitten sich die
                Antworten des Interviews mit unserer Recherche. Es gab ein paar kleine neue Erkenntnisse, so zum
                Beispiel, das aktuell daran gearbeitet wird, die einzelnen Parameter eines LLM besser zu verstehen.</p>

            <h3>Welche M√∂glichkeiten gibt es, um Halluzinationen in LLMs zu vermindern?</h3>
            <p>Wir haben folgende m√∂gliche Ans√§tze gefunden, um Halluzinationen innerhalb von LLMs zu
                reduzieren. Eine wichtige Erkenntnis ist, dass Next-Token-Prediction niemals komplett fehlerfrei werden
                wird. Mithilfe von diesen M√∂glichkeiten k√∂nnen die Halluzinationen jedoch weiter eingegrenzt werden.
                Sowohl private Anwender wie auch Entwickler k√∂nnen hier einen Beitrag leisten. Benutzer k√∂nnen am
                meisten Unterschied beim Prompt Engineering erreichen. Entwickler k√∂nnen mit Umsystemen,
                Architektur-Anpassungen und Trainingsprozess anpassungen gegen Halluzinationen vorgehen. Im Rahmen der
                Arbeit haben wir eine Website mit Tipps erstellt: <a href="/vorschlaege/">f3o.ch/vorschlaege/</a>.
                Damit wollen wir insbesondere Anwendern aufzeigen, was sie unternehmen k√∂nnen, um Falschinformationen
                zu verhindern.</p>

            <h3>Gesamtfazit</h3>
            <p>Wir m√∂chten mit dieser Arbeit erreichen, dass Anwender von LLM und KI sich der Fehlinformationen bewusst
                sind. Heutzutage ist die Verwendung von generativen Tools eine grosse Chance, um unsere Produktivit√§t
                zu f√∂rdern. Jedoch k√∂nnen, wie bereits erw√§hnt, Antworten √ºberzeugend sein, aber aus Fehlinformationen
                bestehen. Selbst wenn die aktuelle Transformer-Architektur perfekt implementiert wird, entstehen durch
                die Next-Token-Prediction Fehler. Auch Quellenangaben von k√ºnstlichen Intelligenzen sind davon betroffen
                und m√ºssen unabh√§ngig √ºberpr√ºft werden. Neben dem √úberpr√ºfen der Fakten muss, aus unserer Sicht, das
                Wissen vermittelt werden, wie ein LLM korrekt gepromptet wird. Hier haben wir versucht mit unserer
                Webseite einen ersten Schritt zu gehen. Obwohl Agent-Architekturen auch durch Anwender erstellt werden
                k√∂nnen, finden wir das besonders Unternehmen noch mehr in diesem Gebiet investieren k√∂nnen. Gerade weil
                Transformer immer Halluzinationen haben werden, sind Agent-Architekturen ideal, um die Halluzinationen
                abzufangen. Zwar haben wir im Interview erfahren, dass RLHF in der Vergangenheit am Meisten gegen
                Fehlinformationen geholfen hat. Aufgrund unserer Recherche w√ºrden wir aber weniger darin investieren, da
                Transformer, selbst beim perfekten Training, Fehler machen werden. Interessant w√§re aus unserer Sicht
                auch das erforschen und entwicklen von neuen LLM-Architekturen, wobei dies Zeit- und Ressourcenintensiv
                ist.</p>
            <p>Aus unserer Sicht ist KI ein geniales Tool f√ºr kreative Sachen oder erste Entw√ºrfe eines Produktes.
                Aktuell empfehlen wir f√ºr gr√∂ssere Arbeiten, gerade bei Recherchen, KI nur sehr gezielt einzusetzen und
                Informationen immer zu √ºberpr√ºfen.</p>
        </section>
    </main>

    <div id="footer-placeholder"></div>

    <script src="/js/main.js"></script>
    <script src="/js/footer.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const allDetails = document.querySelectorAll('.collapsible-message, .collapsible-question');

            allDetails.forEach(details => {
                const summary = details.querySelector('summary');
                const contentWrapper = details.querySelector('.collapsible-content-wrapper');

                // Set initial max-height for animation
                if (!details.open) {
                    contentWrapper.style.maxHeight = '0px';
                }

                summary.addEventListener('click', (event) => {
                    event.preventDefault(); // Prevent the default instant toggle

                    if (details.open) {
                        // Start closing animation
                        contentWrapper.style.maxHeight = '0px';
                        // When the animation is done, remove the 'open' attribute
                        contentWrapper.addEventListener('transitionend', function handler() {
                            details.removeAttribute('open');
                            contentWrapper.removeEventListener('transitionend', handler);
                        });
                    } else {
                        // Set the 'open' attribute to start
                        details.setAttribute('open', '');
                        // Then set the max-height to trigger the opening animation
                        contentWrapper.style.maxHeight = contentWrapper.scrollHeight + 'px';
                    }
                });
            });
        });

        const sliders = document.querySelectorAll('.slider-container');

        sliders.forEach(slider => {
            const sliderTrack = slider.querySelector('.answers-slider');
            const slides = slider.querySelectorAll('.answer');

            const dotsContainer = slider.querySelector('.slider-dots');

            if (!sliderTrack || slides.length === 0) {
                return;
            }

            let currentIndex = 0;
            let touchStartX = 0;
            let touchEndX = 0;

            // Create dots
            slides.forEach((_, index) => {
                const dot = document.createElement('span');
                dot.classList.add('dot');
                if (index === 0) {
                    dot.classList.add('active');
                }
                dot.addEventListener('click', () => {
                    goToSlide(index);
                });
                dotsContainer.appendChild(dot);
            });

            const dots = dotsContainer.querySelectorAll('.dot');

            function goToSlide(index) {
                if (index < 0 || index >= slides.length) {
                    return;
                }
                currentIndex = index;
                const offset = -currentIndex * 100;
                sliderTrack.style.transform = `translateX(${offset}%)`;
                updateDots();
            }

            function updateDots() {
                dots.forEach((dot, index) => {
                    if (index === currentIndex) {
                        dot.classList.add('active');
                    } else {
                        dot.classList.remove('active');
                    }
                });
            }



            // Swipe functionality
            sliderTrack.addEventListener('touchstart', (e) => {
                touchStartX = e.changedTouches[0].screenX;
            });

            sliderTrack.addEventListener('touchend', (e) => {
                touchEndX = e.changedTouches[0].screenX;
                handleSwipe();
            });

            function handleSwipe() {
                if (window.innerWidth >= 768) return; // Only on mobile

                const swipeThreshold = 50; // Minimum swipe distance
                if (touchStartX - touchEndX > swipeThreshold) {
                    // Swiped left
                    const newIndex = (currentIndex + 1) % slides.length;
                    goToSlide(newIndex);
                } else if (touchEndX - touchStartX > swipeThreshold) {
                    // Swiped right
                    const newIndex = currentIndex - 1 < 0 ? slides.length - 1 : currentIndex - 1;
                    goToSlide(newIndex);
                }
            }

            // Initial setup
            goToSlide(0);
        });
    </script>
</body>

</html>