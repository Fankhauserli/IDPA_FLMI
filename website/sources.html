<!DOCTYPE html>
<html lang="de">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Quellen</title>
    <link rel="stylesheet" href="/style.css">
</head>

<body>
    <div id="header-placeholder"></div>

    <main>
        <section>
            <h1 class="page-title">Quellen</h1>
            <input type="text" id="searchInputSources" placeholder="Suchen nach Titel oder Beschreibung..."
                class="search-input">
            <div class="table-responsive-wrapper">
                <table id="sourcesTable">
                    <thead>
                        <tr>
                            <th>Titel</th>
                            <th>Beschreibung</th>
                            <th>Link</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Matrix-Rechner</td>
                            <td>Online Matrix-Multiplikationsrechner</td>
                            <td><a href="https://matrix.reshish.com/matrix-multiplication/"
                                    target="_blank">matrix.reshish.com</a></td>
                        </tr>
                        <tr>
                            <td>MLP (3Blue1Brown)</td>
                            <td>3Blue1Brown (Hrsg.). 2024. How might LLMs store facts. (18.12.2025)</td>
                            <td><a href="https://www.3blue1brown.com/lessons/mlp#title"
                                    target="_blank">3blue1brown.com</a></td>
                        </tr>
                        <tr>
                            <td>MLP (Wikipedia)</td>
                            <td>Wikipedia (Hrsg.). 2025. Multi-Layer-Perzeptron. (18.12.2025)</td>
                            <td><a href="https://de.wikipedia.org/wiki/Multi-Layer-Perzeptron"
                                    target="_blank">de.wikipedia.org</a></td>
                        </tr>
                        <tr>
                            <td>Attention</td>
                            <td>3Blue1Brown (Hrsg.). 2024. Attention in Transformers, step-by-step. (21.12.2025)</td>
                            <td><a href="https://www.3blue1brown.com/lessons/attention#title"
                                    target="_blank">3blue1brown.com</a></td>
                        </tr>
                        <tr>
                            <td>Attention is all you need</td>
                            <td>Original Transformer Paper (NeurIPS 2017)</td>
                            <td><a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf"
                                    target="_blank">neurips.cc</a></td>
                        </tr>
                        <tr>
                            <td>ALIGNMENTFORUM</td>
                            <td>Alignmentforum (Hrsg.). 2023. Fact Finding: Attempting to Reverse-Engineer Factual
                                Recall on the Neuron Level. (21.12.2025)</td>
                            <td><a href="https://www.alignmentforum.org/posts/iGuwZTHWb6DFY3sKB/fact-finding-attempting-to-reverse-engineer-factual-recall"
                                    target="_blank">alignmentforum.org</a></td>
                        </tr>
                        <tr>
                            <td>Training</td>
                            <td>victorzhoug (Hrsg.). 2019. Machine Learning for Beginners: An Introduction to Neural
                                Networks. (24.12.2025)</td>
                            <td><a href="https://victorzhou.com/blog/intro-to-neural-networks/"
                                    target="_blank">victorzhou.com</a></td>
                        </tr>
                        <tr>
                            <td>Halluzination</td>
                            <td>Neptune (Hrsg.). 2024. LLM Hallucinations. (24.12.2025)</td>
                            <td><a href="https://neptune.ai/blog/llm-hallucinations" target="_blank">neptune.ai</a></td>
                        </tr>
                        <tr>
                            <td>Agent Architektur (Part 2)</td>
                            <td>DeepLearning AI (Hrsg.). 2024. Agentic Design Patterns Part 2: Reflection. (24.12.2025)
                            </td>
                            <td><a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/"
                                    target="_blank">deeplearning.ai</a></td>
                        </tr>
                        <tr>
                            <td>Agent Architektur (Part 4)</td>
                            <td>DeepLearning AI (Hrsg.). 2024. Agentic Design Patterns Part 4: Planning. (24.12.2025)
                            </td>
                            <td><a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/"
                                    target="_blank">deeplearning.ai</a></td>
                        </tr>
                        <tr>
                            <td>Agent Architektur (Part 5)</td>
                            <td>DeepLearning AI (Hrsg.). 2024. Agentic Design Patterns Part 5: Multi-Agent
                                Collaboration. (24.12.2025)</td>
                            <td><a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/"
                                    target="_blank">deeplearning.ai</a></td>
                        </tr>
                        <tr>
                            <td>Leaked System Prompts</td>
                            <td>GitHub (Hrsg.) 2025. Leaked-system-prompts. (26.12.2025)</td>
                            <td><a href="https://github.com/jujumilk3/leaked-system-prompts/tree/main"
                                    target="_blank">github.com</a></td>
                        </tr>
                        <tr>
                            <td>Prompts gegen Halluzinationen</td>
                            <td>GodOfPrompt (Hrsg.). 2024. 9 Prompt Engineering Methods to Reduce Hallucinations.
                                (26.12.2025)</td>
                            <td><a href="https://www.godofprompt.ai/blog/9-prompt-engineering-methods-to-reduce-hallucinations-proven-tips"
                                    target="_blank">godofprompt.ai</a></td>
                        </tr>
                        <tr>
                            <td>Prompts gegen Halluzinationen</td>
                            <td>Suse (Hrsg.). 2026. Preventing AI Hallucinations with Effective User Prompts.
                                (08.02.2026)</td>
                            <td><a href="https://documentation.suse.com/suse-ai/1.0/html/AI-preventing-hallucinations/index.html"
                                    target="_blank">documentation.suse.com</a></td>
                        </tr>
                        <tr>
                            <td>Prompt Engineering</td>
                            <td>Hostinger (Hrsg.). 2025. Prompt engineering best practices. (27.12.2025)</td>
                            <td><a href="https://www.hostinger.com/tutorials/prompt-engineering-best-practices"
                                    target="_blank">hostinger.com</a></td>
                        </tr>
                        <tr>
                            <td>Prompt Engineering</td>
                            <td>Medium (Hrsg.). 2025. Powerful ways to remove hallucinations in prompt engineering.
                                (27.12.2025)</td>
                            <td><a href="https://manish-poddar.medium.com/powerful-ways-to-remove-hallucinations-in-prompt-engineering-a349fb313593"
                                    target="_blank">medium.com</a></td>
                        </tr>
                        <tr>
                            <td>Prompt Engineering</td>
                            <td>Tolingo (Hrsg.). Prompt Engineering Guide.</td>
                            <td><a href="https://www.tolingo.com/de/prompt-engineering" target="_blank">tolingo.com</a>
                            </td>
                        </tr>
                        <tr>
                            <td>AI Hallucinations</td>
                            <td>Ayadata. Everything you need to know about AI hallucinations.</td>
                            <td><a href="https://www.ayadata.ai/everything-you-need-to-know-about-ai-hallucinations/"
                                    target="_blank">ayadata.ai</a></td>
                        </tr>
                        <tr>
                            <td>Hallucination Analysis</td>
                            <td>Hugging Face. PHARE Analysis of Hallucination in Leading LLMs.</td>
                            <td><a href="https://huggingface.co/blog/davidberenstein1957/phare-analysis-of-hallucination-in-leading-llms"
                                    target="_blank">huggingface.co</a></td>
                        </tr>
                        <tr>
                            <td>Shannon Entropie</td>
                            <td>Wikipedia. Entropie (Informationstheorie).</td>
                            <td><a href="https://de.wikipedia.org/wiki/Entropie_(Informationstheorie)"
                                    target="_blank">de.wikipedia.org</a></td>
                        </tr>
                        <tr>
                            <td>Softmax-Funktion</td>
                            <td>Wikipedia. Softmax-Funktion.</td>
                            <td><a href="https://de.wikipedia.org/wiki/Softmax-Funktion"
                                    target="_blank">de.wikipedia.org</a></td>
                        </tr>
                        <tr>
                            <td>KNN (Perceptrons)</td>
                            <td>Neural Networks and Deep Learning. Chapter 1: Perceptrons.</td>
                            <td><a href="http://neuralnetworksanddeeplearning.com/chap1.html#perceptrons"
                                    target="_blank">neuralnetworksanddeeplearning.com</a></td>
                        </tr>
                        <tr>
                            <td>KNN (3Blue1Brown)</td>
                            <td>3Blue1Brown. Neural Networks.</td>
                            <td><a href="https://www.3blue1brown.com/lessons/neural-networks#title"
                                    target="_blank">3blue1brown.com</a></td>
                        </tr>
                        <tr>
                            <td>RNN vs Transformer</td>
                            <td>Baeldung. RNNs vs Transformers in NLP.</td>
                            <td><a href="https://www.baeldung.com/cs/rnns-transformers-nlp"
                                    target="_blank">baeldung.com</a></td>
                        </tr>
                        <tr>
                            <td>Mamba vs Transformer</td>
                            <td>Medium. Mamba vs Transformers: Efficiency, Scale, and the Future of AI.</td>
                            <td><a href="https://michielh.medium.com/mamba-vs-transformers-efficiency-scale-and-the-future-of-ai-d7a8dedb4018"
                                    target="_blank">medium.com</a></td>
                        </tr>
                        <tr>
                            <td>GPT</td>
                            <td>3Blue1Brown. GPT Explained.</td>
                            <td><a href="https://www.3blue1brown.com/lessons/gpt#title"
                                    target="_blank">3blue1brown.com</a></td>
                        </tr>
                        <tr>
                            <td>Backpropagation</td>
                            <td>3Blue1Brown (Hrsg.). 2024. What is backpropagation really doing?. (21.12.2025)</td>
                            <td><a href="https://www.3blue1brown.com/lessons/backpropagation#title"
                                    target="_blank">3blue1brown.com</a></td>
                        </tr>
                        <tr>
                            <td>News Integrity in AI</td>
                            <td>EBU (Hrsg.). 2025. News Integrity in AI Assistants. (31.12.2025)</td>
                            <td><a href="https://www.ebu.ch/files/live/sites/ebu/files/Publications/MIS/open/EBU-MIS-BBC_News_Integrity_in_AI_Assistants_Report_2025.pdf"
                                    target="_blank">ebu.ch</a></td>
                        </tr>
                        <tr>
                            <td>RAG</td>
                            <td>Wikipedia. Retrieval-augmented generation.</td>
                            <td><a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation"
                                    target="_blank">en.wikipedia.org</a></td>
                        </tr>
                        <tr>
                            <td>RLHF</td>
                            <td>Hugging Face. Reinforcement Learning from Human Feedback.</td>
                            <td><a href="https://huggingface.co/blog/rlhf" target="_blank">huggingface.co</a></td>
                        </tr>
                        <tr>
                            <td>Interview (Mikaela)</td>
                            <td>Portfolio von Mikaela (Interview-Partnerin).</td>
                            <td><a href="https://dpoportfolio-mikaela.onrender.com/"
                                    target="_blank">dpoportfolio-mikaela.onrender.com</a></td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </section>
    </main>

    <div id="footer-placeholder"></div>

    <script src="/js/main.js"></script>
    <script src="/js/footer.js"></script>
    <script src="/js/table-filter.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', () => {
            setupTableFilter('searchInputSources', 'sourcesTable');
        });
    </script>
</body>

</html>